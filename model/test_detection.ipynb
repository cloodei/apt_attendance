{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ae9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_landmarks(landmarks):\n",
    "    left_eye, right_eye, nose, mouth_left, mouth_right = landmarks\n",
    "\n",
    "    eye_diff_y = abs(left_eye[1] - right_eye[1])\n",
    "    eye_dist_x = abs(left_eye[0] - right_eye[0])\n",
    "\n",
    "    if eye_dist_x == 0:\n",
    "        return False\n",
    "    if eye_diff_y > 0.25 * eye_dist_x:\n",
    "        return False\n",
    "    if not (min(left_eye[0], right_eye[0]) < nose[0] < max(left_eye[0], right_eye[0])):\n",
    "        return False\n",
    "    if not (mouth_left[1] > nose[1] and mouth_right[1] > nose[1]):\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN             \n",
    "\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "\n",
    "\n",
    "url = \"http://10.2.87.162:8080/shot.jpg\"\n",
    "# url = \"http://192.168.1.53:8080/shot.jpg\" \n",
    "detected_frames = []\n",
    "while True:\n",
    " \n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    frame = cv2.imdecode(img_arr, -1)\n",
    "\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5)\n",
    "\n",
    "    \n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    #\n",
    "    boxes, probs, landmarks = mtcnn.detect(img, landmarks=True)\n",
    "    \n",
    "  \n",
    "    if boxes is not None:\n",
    "        for box, prob, lm in zip(boxes, probs, landmarks):\n",
    "            if prob is not None and prob > 0.8:\n",
    "                if is_valid_landmarks(lm):\n",
    "                    x1, y1, x2, y2 = [int(b) for b in box]\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                    for (lx, ly) in lm:\n",
    "                        cv2.circle(frame, (int(lx), int(ly)), 2, (0, 0, 255), -1)\n",
    "\n",
    "                    detected_frames.append(frame.copy())\n",
    "    cv2.imshow(\"MTCNN Face Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3777d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSV_TO_NAME = {\n",
    "    \"7\": \"Nguyen_Van_Tuan\",\n",
    "    \"8\": \"Nguyen_Viet_Quoc_An\",\n",
    "    \"6\": \"Nguyen_Van_Minh\",\n",
    "    \"13\": \"Nguyen_Thi_Phuong_Thao\",\n",
    "    \"11\": \"Nguyen_Thi_Hong_Mai\",\n",
    "    \"10\": \"Nguyen_Thi_Cam_Ly\",\n",
    "    \"9\": \"Nguyen_The_Truong\",\n",
    "    \"5\": \"Nguyen_Phu_Nguyen\",\n",
    "    \"4\": \"Nguyen_Phong_Hai\",\n",
    "    \"12\": \"Nguyen_Ha_Phuong_Uyen\",\n",
    "    \"1\": \"Nguyen_Duy_Hoang\",\n",
    "    \"2\": \"Nguyen_Duc_Phong\",\n",
    "    \"14\": \"Mai_Thanh_Thu\",\n",
    "    \"3\": \"Le_Duc_Nguyen\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e28ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\APtech\\.venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "classifier = joblib.load(\"models/svm_model.pkl\")\n",
    "url = \"http://10.2.87.162:8080/shot.jpg\"\n",
    "\n",
    "while True:\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    frame = cv2.imdecode(img_arr, -1)\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5)\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    boxes, probs, landmarks = mtcnn.detect(img, landmarks=True)\n",
    "    if boxes is not None:\n",
    "        h, w, _ = frame.shape\n",
    "        for box, prob in zip(boxes, probs):\n",
    "            if prob is None or prob < 0.9:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = [int(b) for b in box]\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(w, x2)\n",
    "            y2 = min(h, y2)\n",
    "\n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                continue \n",
    "            face_img = frame[y1:y2, x1:x2]\n",
    "            if face_img.size == 0:\n",
    "                continue\n",
    "\n",
    "            face_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))\n",
    "            face_tensor = mtcnn(face_pil)\n",
    "            if face_tensor is None:\n",
    "                continue\n",
    "\n",
    "            if face_tensor.ndim == 3:  \n",
    "                face_tensor = face_tensor.unsqueeze(0) \n",
    "            face_embedding = resnet(face_tensor.to(device)).detach().cpu().numpy()\n",
    "\n",
    "            pred = classifier.predict(face_embedding)\n",
    "            name = MSV_TO_NAME.get(str(pred[0]), \"Unknown\")\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (x1, y1-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b3e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu 5 frame có khuôn mặt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Đã lưu {len(detected_frames)} frame có khuôn mặt\")\n",
    "\n",
    "while True:  # lặp vô hạn, bấm Q để thoát\n",
    "    for i, f in enumerate(detected_frames):\n",
    "        cv2.imshow(\"Detected Frames\", f)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):  \n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
